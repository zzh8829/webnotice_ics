BEGIN:VCALENDAR
VERSION:2.0
PRODID:-//UW-Webnotice//EN
X-WR-CALNAME:UW Webnotice (Computer Science)
BEGIN:VEVENT
SUMMARY:Towards Correct and Efficient Multi-core Programming -  (Algorithm
 s and Complexity Group Seminar)
DTSTART:20180305T153000Z
DTEND:20180305T163000Z
DTSTAMP:20180305T153000Z
UID:20180305T153000Z_dd43ce4c50ea00f4887335cb93d95345
DESCRIPTION:Speaker:  Trevor Brown\, Postdoctoral fellow\, Institute of Sc
 ience and Technology\, Austria\nTitle:   "Towards Correct and Efficient Mu
 lti-core Programming" \n\nAbstract:  The last decade of technological adva
 ncement has ushered in an era of ubiquitous data\, generated by vast swath
 es of always-on and always-connected consumer devices\, industrial process
 es and academic projects. As the amount of available data and the variety 
 of its potential uses increases\, data processing is quickly becoming miss
 ion-critical for many organizations. Large scale multi-core systems repres
 ent the best available solution to these data processing needs. However\, 
 it is notoriously difficult to program such systems\, even for experts. Th
 e research challenge is to determine how large scale multi-core systems ca
 n be programmed easily\, correctly and efficiently. \n In this talk\, I wi
 ll describe two projects that address different aspects of this challenge.
  The first project introduces new tools for designing concurrent data stru
 ctures that are fast and provably correct. These data structures function 
 as essential algorithmic building blocks in concurrent software. The secon
 d project encompasses techniques for improving the performance of existing
  concurrent data structures and expanding their capabilities. These techni
 ques improve performance in application benchmarks by up to three orders o
 f magnitude over previous approaches. \n      \n Bio : Trevo
 r Brown is a postdoctoral fellow at the Institute of Science and Technolog
 y\, Austria. Prior to joining IST Austria\, he was a postdoctoral fellow a
 t the Technion\, Israel Institute of Technology. His research spans a vari
 ety of topics centered around the question of how large multi-core systems
  can be programmed easily\, correctly and efficiently. These topics includ
 e non-volatile memory\, transactional memory\, memory management\, concurr
 ent data structures\, lock-free algorithms and databases. He obtained his 
 PhD in Computer Science from the University of Toronto in 2017. Before his
  PhD studies\, he worked in industry as a software engineer.  \n \n   \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Enhancing the Discovery and Mitigation of Vulnerabilities in Binar
 y Programs -  (Cryptography\, Security\, and Privacy (CrySP) Group Seminar
 )
DTSTART:20180306T153000Z
DTEND:20180306T163000Z
DTSTAMP:20180306T153000Z
UID:20180306T153000Z_a4f281932edbbe26022d865536b40a4c
DESCRIPTION:Speaker:  Ruoyu (Fish) Wang\, SecLab\, Department of Computer 
 Science\, University of California\, Santa Barbara\nTitle:   "Enhancing th
 e Discovery and Mitigation of Vulnerabilities in Binary Programs" \n\nAbst
 ract:  In the computing landscape of the modern world\, our devices and sy
 stems\, including PCs\, servers\, industrial control systems\, and smart/e
 mbedded devices\, are increasingly relying on programs for which the sourc
 e code is unavailable to end users\, security analysts\, and even manufact
 urers  termed binary programs. Oftentimes\, binary programs are not 
 fully secure\, and through these devices and systems\, vulnerabilities in 
 binaries may have a broad impact on society. Because of the intrinsic comp
 lexity of programs\, the discovery and mitigation of vulnerabilities in bi
 naries is generally viewed as a difficult task. It is only more difficult 
 due to the loss of information\, especially semantics\, through compilatio
 n and optimization.\n In this talk\, I will present my research on improvi
 ng the discovery and mitigation of vulnerabilities in binaries without req
 uiring source code. I approach this goal from different angles. I will fir
 st discuss improvements on traditional vulnerability discovery techniques\
 , such as fuzz testing\, by complementing them with assistance from either
  symbolic execution engines or intelligence from non-expert humans. I will
  then showcase a novel technique for static binary rewriting with extremel
 y low overhead\, which greatly reduces the performance impact of vulnerabi
 lity mitigation and program hardening on binaries. These techniques are bu
 ilt upon the angr binary analysis platform\, which I co-founded and mainta
 in to help foster the future of binary analysis.\n      \n B
 io : Ruoyu (Fish) Wang is a Ph.D. candidate in the SecLab of the Departmen
 t of Computer Science at the University of California\, Santa Barbara\, be
 ing advised by Prof. Giovanni Vigna and Prof. Christopher Kruegel. His res
 earch focuses on system security\, especially on automated binary program 
 analysis and reverse engineering of software. He is the co-founder and a c
 ore developer of the binary analysis platform\, angr. He is a core member 
 of the CTF team Shellphish and the CGC team Shellphish CGC\, with whom he 
 won the third place in the Final Event of the DARPA Cyber Grand Challenge 
 in 2016.  \n \n \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Stereoscopic 3D Line Drawing and Shading -  (Computer Graphics Res
 earch Group PhD Seminar)
DTSTART:20180306T163000Z
DTEND:20180306T173000Z
DTSTAMP:20180306T163000Z
UID:20180306T163000Z_b083023fc3e1bf7c3c6c0358f8f1b83d
DESCRIPTION:Speaker:  Lesley Istead\, David R. Cheriton School of Computer
  Science\nTitle:   "Stereoscopic 3D Line Drawing and Shading" \n\nAbstract
 :  In this talk\, we present a method for producing stylized stereoscopic 
 3D (S3D) line drawings or sketches from S3D photos.\n Our method renders c
 ontours and silhouettes found in the disparity map and addresses some of t
 he issues that arise when working with 8-bit disparity. Finally\, we add s
 hading to our stylized S3D line drawings to improve the perception of dept
 h and surface shape.  \n \n     \n
LOCATION:DC 3323
END:VEVENT
BEGIN:VEVENT
SUMMARY:Securing Hardware-based Trusted Execution Environment -  (Cryptogr
 aphy\, Security\, and Privacy (CrySP) Group Seminar)
DTSTART:20180308T153000Z
DTEND:20180308T163000Z
DTSTAMP:20180308T153000Z
UID:20180308T153000Z_8d65c24308ce783fc1a8a98b1658fdbf
DESCRIPTION:Speaker:  Sangho Lee\, Postdoctoral fellow\, Computer Science\
 , Georgia Institute of Technology\nTitle:   "Securing Hardware-based Trust
 ed Execution Environment" \n\nAbstract:  Recently\, hardware starts to ado
 pt security mechanisms that satisfy both robustness and efficiency. One no
 table example is a hardware-based trusted execution environment (TEE)\, su
 ch as Intel Software Guard Extensions (SGX)\, that allows a user applicati
 on to have a secure and isolated execution environment for confidential co
 mputations without relying on underlying systems software (e.g.\, operatin
 g system and hypervisor) and its administrators. However\, recent studies 
 have shown that existing hardware-based TEEs are vulnerable to side-channe
 l attacks\, making their overall security guarantees questionable.\n In th
 is talk\, I will first show how side-channel attacks against hardware-base
 d TEEs can accurately reveal secrets\, such as private keys\, from confide
 ntial computations by exploiting memory page faults and branch prediction 
 behaviors. Then\, I will explain our countermeasures against the attacks\,
  which are based on program transformations and hardware primitives to ide
 ntify suspicious page faults and obfuscate branch execution histories. Las
 t\, I will discuss my research plan to securely and effectively use hardwa
 re-assisted security mechanisms.\n      \n Bio : Sangho Lee 
 is a postdoctoral fellow in Computer Science at Georgia Institute of Techn
 ology\, working with Prof. Taesoo Kim and Prof. Wenke Lee. His research in
 terests include all aspects of computer security\, especially in systems a
 nd web security. His research discovered and solved many security problems
  in hardware\, operating system\, web browser\, and online platform. His w
 ork was published in top-tier security\, systems\, and web conferences (IE
 EE S&P\, USENIX Security\, ACM CCS\, ISOC NDSS\, USENIX ATC\, and WWW). He
  obtained his Ph.D. degree from POSTECH\, Korea\, in 2013\, and worked as 
 a postdoctoral research associate at POSTECH.  \n \n \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Scalable Replay-Based Replication for Fast OLTP Databases -  (Netw
 orks and Distributed Systems Seminar)
DTSTART:20180308T180000Z
DTEND:20180308T190000Z
DTSTAMP:20180308T180000Z
UID:20180308T180000Z_66105b0547a4fc2c9456ab5156bfcc7f
DESCRIPTION:Speaker:  Ashvin Goel\, University of Toronto\nTitle:   "Scala
 ble Replay-Based Replication for Fast OLTP Databases" \n\nAbstract:  Datab
 ases commonly use primary-backup replication schemes for fault tolerance a
 nd disaster recovery. These schemes raise significant challenges for moder
 n\, in-memory databases\, which generate high transaction rates\, and reco
 very logs at close to memory bandwidth. It is hard to replay the recovery 
 log scalably on the backup\, making the backup a bottleneck. Moreover\, th
 e log transfer can cause network bottlenecks. Both these bottlenecks can s
 ignificantly slow the primary database.\n This work proposes addressing th
 ese problems by using record-replay for replicating fast databases. Our de
 sign enables replay to be performed scalably and concurrently\, allowing t
 he backup performance to scale with the primary. At the same time\, our ap
 proach requires only 15-20% of the network bandwidth required by tradition
 al logging\, reducing network infrastructure costs significantly.  \n \n \
 n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Effective Use of SSDs in Database Systems -  (Data Systems Group P
 hD Defence)
DTSTART:20180308T190000Z
DTEND:20180308T200000Z
DTSTAMP:20180308T190000Z
UID:20180308T190000Z_5f8019c01521b64282dacd46b6d33a06
DESCRIPTION:Speaker:  Pedram Ghodsnia\, David R. Cheriton School of Comput
 er Science\nTitle:   "Effective Use of SSDs in Database Systems" \n\nAbstr
 act:  With the advent of solid state drives (SSDs)\, the storage industry 
 has experienced a revolutionary improvement in I/O performance. Compared t
 o traditional hard disk drives (HDDs)\, SSDs benefit from shorter I/O late
 ncy\, better power efficiency\, and cheaper random I/Os. Because of these 
 superior properties\, SSDs are gradually replacing HDDs. For decades\, dat
 abase management systems have been designed\, architected\, and optimized 
 based on the performance characteristics of HDDs.  In order to utilize the
  superior performance of SSDs\, new methods should be developed\, some dat
 abase components should be redesigned\, and architectural decisions should
  be revisited.\n In this thesis\, novel methods are proposed to exploit th
 e new capabilities of modern SSDs to improve the performance of database s
 ystems. The first is a new method for using SSDs as a fully persistent sec
 ond level memory buffer pool. This method uses SSDs as a supplementary sto
 rage device to improve transactional throughput and to reduce the checkpoi
 nt and recovery times. A prototype of the proposed method is compared with
  its closest existing competitor. The second considers the impact of the p
 arallel I/O capability of modern SSDs on the database query optimizer. It 
 is shown that a query optimizer that is unaware of the parallel I/O capabi
 lity of SSDs can make significantly sub-optimal decisions. In addition\, a
  practical method for making the query optimizer parallel-I/O-aware is int
 roduced and evaluated empirically. The third technique is an SSD-friendly 
 external merge sort. This sorting technique has better performance than ot
 her common external sorting techniques. It also improves the SSD's lifespa
 n by reducing the number of write operations required during sorting.  \n 
 \n       \n
LOCATION:DC 2314
END:VEVENT
BEGIN:VEVENT
SUMMARY:Predicting Human Strategic Behavior: From Behavioral Economics to 
 Deep Learning -  (Artificial Intelligence Lab Seminar)
DTSTART:20180312T143000Z
DTEND:20180312T153000Z
DTSTAMP:20180312T143000Z
UID:20180312T143000Z_535a3174159348bffa4978f55878030a
DESCRIPTION:Speaker:  James Wright\, Postdoctoral researcher\, Microsoft R
 esearch\nTitle:   "Predicting Human Strategic Behavior: From Behavioral Ec
 onomics to Deep Learning" \n\nAbstract:  In order to do a good job of inte
 racting with people\, a system must have an adequate model of how people w
 ill react to its actions. This is particularly true in strategic settings:
  settings that contain multiple agents\, each with their own goals and pri
 orities\, in which each agent's ability to accomplish their goals depends 
 partly on the actions of the other agents. Standard models of strategic be
 havior assume that the participants are perfectly rational. However\, a we
 alth of experimental evidence shows that not only do human agents fail to 
 behave according to these models\, but that they frequently deviate from t
 hese models' predictions in a predictable\, systematic way.  \n In this ta
 lk\, I will survey my work on modeling human behavior in unrepeated\, simu
 ltaneous-move games. These games can be used to analyze a surprising numbe
 r of application domains\, such as the advertising auctions that fund the 
 major search engines\, or the algorithms that are used to optimize the all
 ocation of security personnel in ports and airports.\n      
 \n Bio : James Wright is a postdoctoral researcher at Microsoft Research's
  New York City lab.  His research focuses on modeling and predicting human
  strategic behavior by synthesizing ideas from artificial intelligence (es
 pecially machine learning) and game theory.\n Dr. Wright completed his Ph.
 D. in Computer Science at the University of British Columbia\, where he wa
 s advised by Kevin Leyton-Brown. His dissertation won an Honorable Mention
  for the ACM SIGecom Doctoral Dissertation Award.  \n \n \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Incremental Difficulty in Platformer Games -  (Human-Computer Inte
 raction PhD Seminar)
DTSTART:20180313T140000Z
DTEND:20180313T150000Z
DTSTAMP:20180313T140000Z
UID:20180313T140000Z_c0311b75e5e130a81d5cbb916aa19063
DESCRIPTION:Speaker:  Rina Wehbe\, David R. Cheriton School of Computer Sc
 ience\nTitle:   "Incremental Difficulty in Platformer Games" \n\nAbstract:
   Designing difficulty levels in platformer games is a challenge for game 
 designers. It is important because design decisions that affect difficulty
  also directly affect player experience. Consequently\, design strategies 
 for balancing game difficulty are discussed by both academics and game des
 igners. \n In this paper\, we study how manipulating the following design 
 decisions\, commonly found in platformers\, moderates difficulty: Scroll S
 peed\, Target Size\, Jump Task Complexity\, and Perspective. Results for S
 croll Speed and Target Size indicate that errors increase as speed increas
 es and platform size decreases. However\, results for jump task complexity
  demonstrate a separation of errors from task complexity. Specifically\, w
 hile double-jump tasks are harder than single-jump tasks\, triple-jump tas
 ks appear to be as difficult as double-jump tasks. Additionally\, the stud
 y demonstrates how changes in perspective affect the errors made by player
 s in gameplay. The study results are applicable both to automatic level ge
 neration and dynamic difficulty adjustment in platformer games. \n This pa
 per was published at CHI 2017.  \n \n \n
LOCATION:DC 3317
END:VEVENT
BEGIN:VEVENT
SUMMARY:EC-Store: A Dynamic Distributed Erasure Coded Storage System -  (D
 ata Systems Group PhD Seminar)
DTSTART:20180314T170000Z
DTEND:20180314T180000Z
DTSTAMP:20180314T170000Z
UID:20180314T170000Z_2ba50f86da5f11b8fdc6c2f611949a49
DESCRIPTION:Speaker:  Michael Abebe\, David R. Cheriton School of Computer
  Science\nTitle:   "EC-Store: A Dynamic Distributed Erasure Coded Storage 
 System" \n\nAbstract:  Cloud storage systems typically choose between repl
 icating or erasure encoding data to provide fault tolerance. Replication e
 nsures that data can be accessed from a single site but incurs a much high
 er storage overhead\, which is a costly downside for large-scale storage s
 ystems. Erasure coding has a lower storage requirement but relies on encod
 ing/decoding and distributed data retrieval that can result in increased r
 esponse times. \n In this talk I will present EC-Store\, a dynamic distrib
 uted erasure coded storage system that significantly reduces data retrieva
 l times when compared to replicated and erasure coded storage systems. EC-
 Store achieves these reductions in latency by making intelligent data acce
 ss decisions and dynamically moving data in response to system load and ac
 cess patterns  \n \n \n
LOCATION:MC 5417
END:VEVENT
BEGIN:VEVENT
SUMMARY:Left Them 4 Dead: Perception of Humans versus Non-Player Character
  Teammates in Cooperative Gameplay  -  (Human-Computer Interaction PhD Se
 minar)
DTSTART:20180320T140000Z
DTEND:20180320T150000Z
DTSTAMP:20180320T140000Z
UID:20180320T140000Z_511add041ea68f11952217167c3bce5e
DESCRIPTION:Speaker:  Rina Wehbe\, David R. Cheriton School of Computer Sc
 ience\nTitle:   "Left Them 4 Dead: Perception of Humans versus Non-Player 
 Character Teammates in Cooperative Gameplay " \n\nAbstract:  Why do we ca
 re if our teammates are not human? This study seeks to uncover whether or 
 not the perception of other players as human or artificial entities can in
 fluence player experience. We use both deception and a between-participant
 s blind study design to reduce bias in our experiment. \n Our qualitative 
 results show that people do care about the perceived nature of other playe
 rs\, even though they are not always able to correctly identify them as hu
 man or as non-player character teammates. Interview data suggest believing
  that one is playing with other humans can positively affect a player's su
 bjective experience. Furthermore\, our qualitative results indicate that p
 layers view their non-player character teammates as humanized entities\, b
 ut adopt a neo-feudalistic (i.e.\, an unequal rights) view of them. Based 
 on our results\, we establish game design guidelines for non-player charac
 ter teammates leading to stronger\, emotional human-computer relationships
  in video games. \n This paper was published DIS2017.  \n \n \n
LOCATION:DC 3317
END:VEVENT
BEGIN:VEVENT
SUMMARY:Learning Sparse Wavelet Representations -  (Artificial Intelligenc
 e Lab PhD Seminar)
DTSTART:20180320T200000Z
DTEND:20180320T210000Z
DTSTAMP:20180320T200000Z
UID:20180320T200000Z_efd10ec89040d522d39aac336981c808
DESCRIPTION:Speaker:  Daniel Recoskie\, David R. Cheriton School of Comput
 er Science\nTitle:   "Learning Sparse Wavelet Representations" \n\nRemarks
 :  RCH is the J.R. Coutts Engineering Lecture Hall (https://uwaterloo.ca/h
 uman-resources/services/jr-coutts-engineering-lecture-hall-rch)  \n\nAbstr
 act:  We propose a method for learning wavelet filters directly from data.
  We accomplish this by framing the discrete wavelet transform as a modifie
 d convolutional neural network. We introduce an autoencoder wavelet transf
 orm network that is trained using gradient descent. The model is capable o
 f learning structured wavelet filters from synthetic and real data. The le
 arned wavelets are shown to be similar to traditional wavelets that are de
 rived using Fourier methods. Our method is simple to implement and easily 
 incorporated into neural network architectures. A major advantage to our m
 odel is that we can learn from raw audio data.  \n \n \n
LOCATION:RCH 207
END:VEVENT
BEGIN:VEVENT
SUMMARY:Raising Permutations to Powers in Place -  (Algorithms and Complex
 ity Group PhD Seminar)
DTSTART:20180321T173000Z
DTEND:20180321T183000Z
DTSTAMP:20180321T173000Z
UID:20180321T173000Z_ac4b69e65f82588d41a5be0d291e7d1d
DESCRIPTION:Speaker:  Hicham El-Zein\, David R. Cheriton School of Compute
 r Science\nTitle:   "Raising Permutations to Powers in Place" \n\nAbstract
 :  Given a permutation of $n$ elements\, stored as an array\, we address t
 he problem of replacing the permutation by its $k^{\\mathrm{th}}$ power. W
 e aim to perform this operation quickly using $o(n)$ bits of extra storage
 . To this end\, we first present an algorithm for inverting permutations t
 hat uses $O(\\lg^2 n)$ additional bits and runs in $O(n\\lg n)$ worst case
  time. This result is then generalized to the situation in which the permu
 tation is to be replaced by its $k^{\\mathrm{th}}$ power.\n An algorithm w
 hose worst case running time is $O(n\\lg n)$ and uses $O(\\lg^2 n + \\min\
 \{k\\lg n\,n^{\\rfrac{3}{4}+\\epsilon}\\})$ additional bits is presented. 
  \n \n  \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Spaun 2.0: Extending the World's Largest Functional Brain Model - 
  (Artificial Intelligence Lab PhD Defence)
DTSTART:20180404T160000Z
DTEND:20180404T170000Z
DTSTAMP:20180404T160000Z
UID:20180404T160000Z_5222aa0bc7a06496eba1ed83109c035f
DESCRIPTION:Speaker:  Feng-Xuan Choo\, David R. Cheriton School of Compute
 r Science\nTitle:   "Spaun 2.0: Extending the World's Largest Functional B
 rain Model" \n\nAbstract:  Building large-scale brain models is one method
  used by theoretical neuroscientists to understand the way the human brain
  functions. Researchers typically use either a bottom-up approach\, which 
 focuses on the detailed modelling of various biological properties of the 
 brain and places less importance on reproducing functional behaviour\, or 
 a top-down approach\, which generally aim to reproduce the behaviour obser
 ved in real cognitive agents\, but typically sacrifices adherence to const
 raints imposed by the neuro-biology. \n The focus of this thesis is Spaun\
 , a large-scale brain model constructed using a combination of the bottom-
 up and top-down approaches to brain modelling. Spaun is currently the worl
 d's largest functional brain model\, capable of performing 8 distinct cogn
 itive tasks ranging from digit recognition to inductive reasoning. The the
 sis is organized to discuss three aspects of the Spaun model.\n First\, it
  describes the original Spaun model\, and explores how a top-down approach
 \, known as the Semantic Pointer Architecture (SPA)\, has been combined wi
 th a bottom-up approach\, known as the Neural Engineering Framework (NEF)\
 , to integrate 6 existing cognitive models into a unified cognitive model 
 that is Spaun.\n Next\, the thesis identifies some of the concerns with th
 e original Spaun model\, and show the modifications made to the network to
  remedy these issues. It also characterizes how the Spaun model was re-org
 anized and re-implemented (to include the aforementioned modifications) as
  the Spaun 2.0 model. As part of the discussion of the Spaun 2.0 model\, t
 ask performance results are presented that compare the original Spaun mode
 l and the re-implemented Spaun 2.0 model\, demonstrating that the modifica
 tions to the Spaun 2.0 model have improved its accuracy on the working mem
 ory task\, and the two induction tasks.\n Finally\, three extensions to Sp
 aun 2.0 are presented. These extensions take advantage of the re-organized
  Spaun model\, giving Spaun 2.0 new capabilities: a motor system capable o
 f adapting to unknown force fields applied to its arm\; a visual system ca
 pable of processing $256\\times256$ full-colour images\; and the ability t
 o follow general instructions.\n The Spaun model and architecture presente
 d in this thesis demonstrate that by using the SPA and the NEF\, it is not
  only possible to construct functional large-scale brain models\, but to d
 o so in a manner that supports complex extensions to the model. The final 
 Spaun 2.0 model consists of about 6.6 million neurons\, can perform 12 cog
 nitive tasks\, and has been demonstrated to reproduce behavioural and neur
 ological data observed in natural cognitive agents.  \n \n \n
LOCATION:DC 2314
END:VEVENT
BEGIN:VEVENT
SUMMARY:Succinct Color Searching in One Dimension -  (Algorithms and Compl
 exity Group PhD Seminar)
DTSTART:20180404T173000Z
DTEND:20180404T183000Z
DTSTAMP:20180404T173000Z
UID:20180404T173000Z_a742c78c55a9fe66a48770c0388f83fa
DESCRIPTION:Speaker:  Hicham El-Zein\, David R. Cheriton School of Compute
 r Science\nTitle:   "Succinct Color Searching in One Dimension" \n\nAbstra
 ct:  We present succinct data structures for one-dimensional color reporti
 ng and color counting problems. We are given a set of $n$ points with inte
 ger coordinates in the range $[1\,m]$ and every point is assigned a color 
 from the set $\\{\\\,1\,\\ldots\,\\sigma\\\,\\}$. A color reporting query 
 asks for the list of distinct colors that occur in a query interval $[a\,b
 ]$ and a color counting query asks for the number of distinct colors in $[
 a\,b]$.\n We describe a succinct data structure that answers approximate c
 olor counting queries in $O(1)$ time and uses $\\mathcal{B}(n\,m) + O(n) +
  o(\\mathcal{B}(n\,m))$ bits\, where $\\mathcal{B}(n\,m)$ is the minimum n
 umber of bits required to represent an arbitrary set of size $n$ from a un
 iverse of $m$ elements. Thus we show\, somewhat counterintuitively\, that 
 it is not necessary to store colors of points in order to answer approxima
 te color counting queries. In the special case when points are in the rank
  space (i.e.\, when $n=m$)\, our data structure needs only $O(n)$ bits. Al
 so\, we show that $\\Omega(n)$ bits are necessary in that case.\n Then we 
 turn to succinct data structures for color reporting. We describe a data s
 tructure that uses $\\mathcal{B}(n\,m) + nH_d(S) + o(\\mathcal{B}(n\,m)) +
  o(n\\lg\\sigma)$ bits and answers queries in $O(k+1)$ time\, where $k$ is
  the number of colors in the answer\, and $nH_d(S)$ ($d=\\log_{\\sigma} n$
 ) is the $d$-th order empirical entropy of the color sequence. Finally\, w
 e consider succinct color reporting under restricted updates.\n Our dynami
 c data structure uses $nH_d(S)+o(n\\lg\\sigma)$ bits and supports queries 
 in $O(k+1)$ time.  \n \n \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Web Data Integration for the Non-Expert -  (Data Systems Group PhD
  Defence)
DTSTART:20180409T170000Z
DTEND:20180409T180000Z
DTSTAMP:20180409T170000Z
UID:20180409T170000Z_6eac07aeff6d783c31ab434539e94730
DESCRIPTION:Speaker:  Ahmed El-Roby\, David R. Cheriton School of Computer
  Science\nTitle:   "Web Data Integration for the Non-Expert" \n\nAbstract:
   Today\, there is an abundance of structured data available on the web in
  the form of RDF graphs and relational (i.e.\, tabular) data. This data co
 mes from heterogeneous sources\, and realizing its full value requires int
 egrating these sources so that they can be queried together. Due to the sc
 ale and heterogeneity of the data sources on the web\, integrating them is
  typically an automatic process. However\, automatic data integration appr
 oaches are not completely accurate since they infer semantics from syntax 
 in data sources with a high degree of heterogeneity. Therefore\, these aut
 omatic approaches can be considered as a first step to quickly get reasona
 ble quality data integration output that can be used in issuing queries ov
 er the data sources. A second step is refining this output over time while
  it is being used. Interacting with the data sources through the output of
  the data integration system and refining this output requires expertise i
 n data management\, which limits the scope of this activity to power users
  and consequently limits the usability of data integration systems.\n This
  thesis focuses on helping non-expert users to access heterogeneous data s
 ources through data integration systems\, without requiring the users to h
 ave prior knowledge of the queried data sources or exposing them to the de
 tails of the output of the data integration system. In addition\, the user
 s can provide feedback over the answers to their queries\, which can then 
 be used to refine and improve the quality of the data integration output. 
 \n The thesis studies both RDF and relational data. For RDF data\, the the
 sis focuses on helping non-expert users to query heterogeneous RDF data so
 urces\, and utilizing their feedback over query answers to improve the qua
 lity of the interlinking between these data sources. For relational data\,
  the thesis focuses on improving the quality of the mediated schema for a 
 set of relational data sources and the semantic mappings between these sou
 rces based on user feedback over query answers.  \n \n 
LOCATION:DC 2310
END:VEVENT
END:VCALENDAR
