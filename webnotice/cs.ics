BEGIN:VCALENDAR
VERSION:2.0
PRODID:-//UW-Webnotice//EN
X-WR-CALNAME:UW Webnotice (Computer Science)
BEGIN:VEVENT
SUMMARY:From SAT to Stochastic SAT -  (Artificial Intelligence Lab Seminar
 )
DTSTART:20180129T180000Z
DTEND:20180129T190000Z
DTSTAMP:20180129T180000Z
UID:20180129T180000Z_32c2ab1d6828b12a1d64ecf035d6723b
DESCRIPTION:Speaker:  Ricardo Salmon\, David R. Cheriton School of Compute
 r Science\nTitle:   "From SAT to Stochastic SAT" \n\nAbstract:  Stochastic
  satisfiability (SSAT) problems are an extension of SAT problems that is P
 SPACE-complete and in the same complexity class as quantified Boolean form
 ula (QBF) and partially observable Markov decision processes (POMDPs).\n W
 e show how to extend techniques from SAT into a stochastic solver called P
 rime\, that solves probabilistic inference and POMDP problems. Similar to 
 SAT and other NP-hard problems\, where a lot of research has been invested
 \, we hope to encourage further research into SSAT. The results show that 
 our solver is able to tackle large problems and is very competitive.  \n \
 n \n
LOCATION:DC 2306C
END:VEVENT
BEGIN:VEVENT
SUMMARY:Low-Cost Maps in Computer Science and Data Analysis -  (Algorithms
  and Complexity Group Seminar)
DTSTART:20180130T153000Z
DTEND:20180130T163000Z
DTSTAMP:20180130T153000Z
UID:20180130T153000Z_05f1c0b05e04d51d2812fce0947ecb68
DESCRIPTION:Speaker:  Amir Nayyeri\, Oregon State University\nTitle:   "Lo
 w-Cost Maps in Computer Science and Data Analysis" \n\nAbstract:  The gene
 ral mathematical problem of computing low-cost maps between two metric spa
 ces is prevalent in many applications\, including registration in medical 
 image processing\, function detection in protein modeling\, reconstructing
  evolutionary trees in phylogenomics\, finding recurrent patterns in data 
 analysis\, and finding simple representations of data in visualization. Ma
 ny instances of the general problem are provably hard\, so we have a dicho
 tomy. On one hand\, we have general algorithms with theoretical worst-case
  guarantees that are prohibitively slow in practice\, and on the other we 
 have faster heuristics engineered for specific applications\, but lacking 
 guarantees. In dichotomy is opportunity  we use parameterized complexity
  to create a finer understanding of the complexity of computing low-cost m
 aps between metric spaces based on their geometric and topological propert
 ies. We specifically target new algorithms with better performance guarant
 ees\, in particular\, for cases of practical interest.\n In this talk\, I 
 focus on two instances of low-cost maps: embeddings with low multiplicativ
 e distortion\, and homeomorphisms with low Frechet length. Specifically\, 
 I present new results on embedding into tree-like metrics\, and computing 
 the Frechet distance between surfaces.\n      \n Bio : Amir 
 Nayyeri works on algorithm design. Specifically\, he is interested in fund
 amental algorithmic problems about geometric and topological structures su
 ch as metric spaces\, graphs\, or simplicial complexes that are inspired b
 y applications in computer science and data analysis.  \n Amir is currentl
 y an assistant professor at Oregon State University. He received his PhD f
 rom University of Illinois at Urbana Champaign\, advised by Jeff Erickson.
  Before joining OSU\, he was a postdoctoral fellow at Carnegie Mellon Univ
 ersity.  \n \n   \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:A Basic Learning Problem that is Independent of the Set Theory ZFC
  Axioms -  (Algorithms and Complexity Group Seminar)
DTSTART:20180131T193000Z
DTEND:20180131T203000Z
DTSTAMP:20180131T193000Z
UID:20180131T193000Z_8ed4e3b9c94d5c04192135c6aebdafea
DESCRIPTION:Speaker:  Shai Ben-David\, David R. Cheriton School of Compute
 r Science\nTitle:   "A Basic Learning Problem that is Independent of the S
 et Theory ZFC Axioms" \n\nAbstract:  We consider the Expectation Maximizat
 ion (EMX) problem that captures many well-studied learning problems. We st
 udy the interaction between the statistical sample complexity of a class o
 f functions and its combinatorial structure. Surprisingly\, we show that t
 he EMX learnability\, as well as the learning rates of some basic class of
  functions F\, depend on the cardinality of the continuum in the model of 
 set theory one "lives in" and is therefore  independent of the set theory 
 ZFC axioms (that are widely accepted as a formalization of the notion of a
  mathematical proof).\n This result implies that there exist no finitery
  combinatorial parameter that characterizes EMX learnability in a way si
 milar to the VC-dimension characterization of binary valued classification
  problems.\n The talk is based on joint work with Pavel Hrube\, Shay Mor
 an\, Amir Shpilka and Amir Yehudayoff.  \n \n          \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:CSIS Bulk Data Collection and National Security Surveillance -  (C
 ryptography\, Security\, and Privacy (CrySP) Group Seminar)
DTSTART:20180206T190000Z
DTEND:20180206T200000Z
DTSTAMP:20180206T190000Z
UID:20180206T190000Z_6d2ad687ab2f0243bd3945b54ea0d546
DESCRIPTION:Speaker:  Micheal Vonn\, BC Civil Liberties Association\nTitle
 :   "CSIS Bulk Data Collection and National Security Surveillance" \n\nAbs
 tract:  Canadians arguably have a much better idea about what kinds of mas
 s surveillance activities are occurring among some of Canada's intelligenc
 e partners in the "Five Eyes" than about what is occurring in Canada. It i
 s clear\, for example\, that the UK's security intelligence has been colle
 cting vast troves of government\, commercial and telecommunications record
 s\, but Canadian practices are relatively unknown. A Canadian Federal Cour
 t ruling in 2016 found the Canadian Security Intelligence Service (CSIS) t
 o have breached its duty of candour to the court in failing\, for over 10 
 years\, to inform the court that it was indefinitely retaining information
  on third parties unrelated to threats to the security of Canada to add to
  its bulk data holdings. This explosive ruling was delivered during the co
 untry's first ever national security consultation\, which resulted in a sw
 eeping new national security omnibus bill (C-59). This talk will outline h
 ow C-59 proposes to address bulk data collection by Canadian intelligence 
 and talk about the civil liberties implications of the new legal standards
  and accountability mechanisms.\n      \n Bio: Micheal Vonn 
 is a lawyer and has been the Policy Director of the BCCLA since 2004. She 
 has been an Adjunct Professor at the University of British Columbia (UBC) 
 in the Faculty of Law and in the School of Library\, Archival and Informat
 ion Studies\, where she has taught civil liberties and information ethics.
  She is a regular guest instructor for UBC's College of Health Disciplines
  Interdisciplinary Elective in HIV/AIDS Care. She has been honoured for he
 r work in HIV/AIDS with both an AccolAIDS Award and a Red Ribbon Award\, a
 nd she is the recipient of the 2015 Keith Sacré Library Champion Award fo
 r support\, guidance and assistance given to the BC library community. \n 
 Her publication credits include the  Birkbeck Law Review \,  Surveillance 
 and Society \,  Journal of Parliamentary and Political Law \, and Case Wes
 tern Reserve  Journal of International Law . Ms. Vonn is a frequent speake
 r on a variety of civil liberties topics including privacy\, national secu
 rity\, policing\, surveillance and free speech. She is currently a collabo
 rator on Big Data Surveillance\, a multi-year research projected lead by Q
 ueens University. She is an Advisory Board Member of Ryerson University's 
 Centre for Free Expression and an Advisory Board Member of Privacy Interna
 tional.  \n \n \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Evolutionary Graph Theory -  (Algorithms and Complexity Group Semi
 nar)
DTSTART:20180207T183000Z
DTEND:20180207T193000Z
DTSTAMP:20180207T183000Z
UID:20180207T183000Z_741c3972c8d0cd8d9e085b552e840620
DESCRIPTION:Speaker:  Josef Tkadlec\, PhD candidate\, Institute of Science
  and Technology\, Austria\nTitle:   "Evolutionary Graph Theory" \n\nAbstra
 ct:  Let $G$ be a graph on $n$ vertices with one random vertex coloured bl
 ack and all the other vertices coloured white. In the language of populati
 on genetics\, this corresponds to a single (advantageous) mutant appearing
  in a structured population of indistinguishable residents. Moran process 
 is a certain discrete-time stochastic process that changes the colouring o
 f the vertices in such a way that eventually the vertices become either al
 l white (the mutant went extinct) or all black (the mutant fixated). \
 n Evolutionary graph theory studies how the fixation probability $\\fp(G)$
  depends on the underlying graph structure. For example it is known that $
 \\fp(K_n)=\\fp(C_n)<\\fp(S_n)$ where $K_n$\, $C_n$\, $S_n$ are the complet
 e graph\, the cycle\, and the star\, respectively. In this talk we will gi
 ve an overview of the research done in the field and present some recent r
 esults concerning graphs for which the fixation probability tends to 1 as 
 the number of vertices tends to infinity.  \n \n  \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Faster Approximate  Diameter and Distance Oracles in Planar Graphs
  -  (Algorithms and Complexity Group PhD Seminar)
DTSTART:20180221T183000Z
DTEND:20180221T193000Z
DTSTAMP:20180221T183000Z
UID:20180221T183000Z_620b73fec13727f04569202216d5a2c3
DESCRIPTION:Speaker:  Dimitrios Skrepetos\, David R. Cheriton School of Co
 mputer Science\nTitle:   "Faster Approximate  Diameter and Distance Oracle
 s in Planar Graphs" \n\nAbstract:  We present an algorithm that computes a
  (1+\\varepsilon)-approximation of the diameter of a weighted\, undirected
  planar graph of n vertices with non-negative edge lengths in O(n \\log n 
 (\\log n + (1/\\varepsilon)^5)) expected time\, improving upon the O(n ((1
 /\\varepsilon)^4 \\log^4 n + 2^{O(1/\\varepsilon)}))-time algorithm of Wei
 mann and Yuster [ICALP 2013]. \n Our algorithm makes two improvements over
  that result: first and foremost\, it replaces the exponential dependency 
 on 1/\\varepsilon with a polynomial one\, by adapting and specializing Cab
 ello's recent abstract-Voronoi-diagram-based technique [SODA 2017] for app
 roximation purposes\; second\, it shaves off two logarithmic factors by ch
 oosing a better sequence of error parameters  during recursion. \n Moreove
 r\, using similar techniques\, we improve the (1+\\varepsilon)-approximate
  distance oracle of Gu and Xu [ISAAC 2015] by first replacing the exponent
 ial dependency on 1/\\varepsilon on the preprocessing time and space with 
 a polynomial one and second removing a logarithmic factor from the preproc
 essing time.  \n \n \n
LOCATION:DC 1304
END:VEVENT
BEGIN:VEVENT
SUMMARY:Effective Use of SSDs in Database Systems -  (Data Systems Group P
 hD Defence)
DTSTART:20180308T190000Z
DTEND:20180308T200000Z
DTSTAMP:20180308T190000Z
UID:20180308T190000Z_f288f71c7ef961e1bd1447b0432c73f3
DESCRIPTION:Speaker:  Pedram Ghodsnia\, David R. Cheriton School of Comput
 er Science\nTitle:   "Effective Use of SSDs in Database Systems" \n\nAbstr
 act:  With the advent of solid state drives (SSDs)\, the storage industry 
 has experienced a revolutionary improvement in I/O performance. Compared t
 o traditional hard disk drives (HDDs)\, SSDs benefit from shorter I/O late
 ncy\, better power efficiency\, and cheaper random I/Os. Because of these 
 superior properties\, SSDs are gradually replacing HDDs. For decades\, dat
 abase management systems have been designed\, architected\, and optimized 
 based on the performance characteristics of HDDs.  In order to utilize the
  superior performance of SSDs\, new methods should be developed\, some dat
 abase components should be redesigned\, and architectural decisions should
  be revisited.\n In this thesis\, novel methods are proposed to exploit th
 e new capabilities of modern SSDs to improve the performance of database s
 ystems. The first is a new method for using SSDs as a fully persistent sec
 ond level memory buffer pool. This method uses SSDs as a supplementary sto
 rage device to improve transactional throughput and to reduce the checkpoi
 nt and recovery times. A prototype of the proposed method is compared with
  its closest existing competitor. The second considers the impact of the p
 arallel I/O capability of modern SSDs on the database query optimizer. It 
 is shown that a query optimizer that is unaware of the parallel I/O capabi
 lity of SSDs can make significantly sub-optimal decisions. In addition\, a
  practical method for making the query optimizer parallel-I/O-aware is int
 roduced and evaluated empirically. The third technique is an SSD-friendly 
 external merge sort. This sorting technique has better performance than ot
 her common external sorting techniques. It also improves the SSD's lifespa
 n by reducing the number of write operations required during sorting.  \n 
 \n 
LOCATION:DC 2314
END:VEVENT
END:VCALENDAR
